{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this document I'll be showing how I scraping/parsing images from stockx.com for my Machine Learning Nano Degree Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I went look into a paticular shoe's product link and image link it loosk like this:\n",
    "\n",
    "https://stockx.com/nike-air-max-1-97-sean-wotherspoon-na\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](StockX_Prod.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the image link:\n",
    "\n",
    "\n",
    "https://stockx-360.imgix.net/Nike-Air-Max-1-97-Sean-Wotherspoon-NA/Images/Nike-Air-Max-1-97-Sean-Wotherspoon-NA/Lv2/img01.jpg?auto=format,compress&q=90&updated_at=1538080256&w=1300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can observe here the product link is constructed by the shoe name itself as the sublink, and also for the iamge link, in the folder it's in sequence for 0 to 360 degree image coded as img01.jpg to img35.jpg.\n",
    "\n",
    "I'll use these two features to write my script for scraping images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockxsdk import Stockx\n",
    "import pandas as pd\n",
    "\n",
    "stockx = Stockx()\n",
    "\n",
    "email = '***************'\n",
    "password = '***************'\n",
    "stockx.authenticate(email, password)\n",
    "\n",
    "keyword=['Zoom Generation','Adidas NMD R1','Adidas Superstar','Adidas Campus','Adidas Yung 1','Adidas Prophere','Adidas Stan Smith',\n",
    "         'Adidas Night Jogger','Adidas EQT','Adidas ZX500','Adidas Ozweego','Adidas Harden','Adidas Forum']\n",
    "\n",
    "# Keyword for searching sneakers on stockx.com\n",
    "\n",
    "resp=stockx.search('Yeezy')\n",
    "r=pd.DataFrame(resp)\n",
    "\n",
    "for k in keyword:\n",
    "    t=pd.DataFrame(stockx.search(k))\n",
    "    r=pd.concat([r,t])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stockxsdk (https://pypi.org/project/stockx-py-sdk/) search function here to generated list of product url by keywords\n",
    "\n",
    "After cleaned invalid product (not shoe category) and 0 sales item, I have a clean csv file here (output.csv)\n",
    "\n",
    "We'll be using label to create folder and url to parse the image in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colorway</th>\n",
       "      <th>deadstock_sold</th>\n",
       "      <th>gender</th>\n",
       "      <th>style_id</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>url</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adidas</td>\n",
       "      <td>['adidas', 'Yeezy']</td>\n",
       "      <td>Clay/Clay/Clay</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>men</td>\n",
       "      <td>EG7490</td>\n",
       "      <td>https://stockx.imgix.net/adidas-Yeezy-Boost-35...</td>\n",
       "      <td>adidas-yeezy-boost-350-v2-clay</td>\n",
       "      <td>0</td>\n",
       "      <td>Adidas-Yeezy-350-V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adidas</td>\n",
       "      <td>['adidas', 'Yeezy']</td>\n",
       "      <td>Grey/Grey/Grey</td>\n",
       "      <td>8542.0</td>\n",
       "      <td>men</td>\n",
       "      <td>EG7492</td>\n",
       "      <td>https://stockx.imgix.net/adidas-Yeezy-Boost-35...</td>\n",
       "      <td>adidas-yeezy-boost-350-v2-true-form</td>\n",
       "      <td>1</td>\n",
       "      <td>Adidas-Yeezy-350-V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addias</td>\n",
       "      <td>['adidas', 'Yeezy']</td>\n",
       "      <td>Geode/Geode/Geode</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>men</td>\n",
       "      <td>EG6860</td>\n",
       "      <td>https://stockx.imgix.net/adidas-Yeezy-Boost-70...</td>\n",
       "      <td>adidas-yeezy-boost-700-v2-geode</td>\n",
       "      <td>2</td>\n",
       "      <td>Adidas-Yeezy-700-V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adidas</td>\n",
       "      <td>['adidas', 'Yeezy']</td>\n",
       "      <td>Grey/Grey/Grey</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>men</td>\n",
       "      <td>EG7491</td>\n",
       "      <td>https://stockx.imgix.net/adidas-Yeezy-Boost-35...</td>\n",
       "      <td>adidas-yeezy-boost-350-v2-hyperspace</td>\n",
       "      <td>3</td>\n",
       "      <td>Adidas-Yeezy-350-V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adidas</td>\n",
       "      <td>['adidas', 'Yeezy']</td>\n",
       "      <td>Grey/Grey/Inertia</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>men</td>\n",
       "      <td>EG7597</td>\n",
       "      <td>https://stockx.imgix.net/adidas-Yeezy-Boost-70...</td>\n",
       "      <td>adidas-yeezy-boost-700-inertia</td>\n",
       "      <td>4</td>\n",
       "      <td>Adidas-Yeezy-700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand           categories           colorway  deadstock_sold gender  \\\n",
       "0  adidas  ['adidas', 'Yeezy']     Clay/Clay/Clay          1560.0    men   \n",
       "1  adidas  ['adidas', 'Yeezy']     Grey/Grey/Grey          8542.0    men   \n",
       "2  addias  ['adidas', 'Yeezy']  Geode/Geode/Geode          1718.0    men   \n",
       "3  adidas  ['adidas', 'Yeezy']     Grey/Grey/Grey          1284.0    men   \n",
       "4  adidas  ['adidas', 'Yeezy']  Grey/Grey/Inertia          7665.0    men   \n",
       "\n",
       "  style_id                                      thumbnail_url  \\\n",
       "0   EG7490  https://stockx.imgix.net/adidas-Yeezy-Boost-35...   \n",
       "1   EG7492  https://stockx.imgix.net/adidas-Yeezy-Boost-35...   \n",
       "2   EG6860  https://stockx.imgix.net/adidas-Yeezy-Boost-70...   \n",
       "3   EG7491  https://stockx.imgix.net/adidas-Yeezy-Boost-35...   \n",
       "4   EG7597  https://stockx.imgix.net/adidas-Yeezy-Boost-70...   \n",
       "\n",
       "                                    url  idx                label  \n",
       "0        adidas-yeezy-boost-350-v2-clay    0  Adidas-Yeezy-350-V2  \n",
       "1   adidas-yeezy-boost-350-v2-true-form    1  Adidas-Yeezy-350-V2  \n",
       "2       adidas-yeezy-boost-700-v2-geode    2  Adidas-Yeezy-700-V2  \n",
       "3  adidas-yeezy-boost-350-v2-hyperspace    3  Adidas-Yeezy-350-V2  \n",
       "4        adidas-yeezy-boost-700-inertia    4     Adidas-Yeezy-700  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('output.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to create folder for different sneakers, the folder name will be using the name in the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using urllib and bs4 to scraping all the images, first we request product page, then getting image src link from bs4, using it to loop through img01 to img35, if it's not an .jpg file we put .png instead. The filename convention weill be the index in our csv file + angle (0-35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for index, row in df.iterrows():  \n",
    "    a=[s.capitalize() for s in s.split('/')[3].split('Product')[0].split('-')]\n",
    "    createFolder()\n",
    "    b='-'.join(a)[:-1]\n",
    "    f='-'.join(a[0:3])\n",
    "    createFolder('E:/StockX/'+f)\n",
    "    temp_url='https://stockx.com/'+df[\"url\"][index]\n",
    "    result = requests.get(temp_url)\n",
    "    c=result.content\n",
    "    soup = BeautifulSoup(c,\"lxml\")\n",
    "    try:\n",
    "        url=soup.find_all(\"img\")[12].get('src')\n",
    "        if('img01' in url):\n",
    "            url=url.split('?')[0]\n",
    "            x,y=url.split('img01')\n",
    "            print (x,y)\n",
    "            for i in img_cd:\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(x+'img'+i+y, 'E:/StockX/'+f+'/'+str(index)+'_'+i+'.jpg')\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, 'E:/StockX/'+f+'/'+str(index)+'_'+i+'.png')\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm doing some manual clean up, removing wrong category, combine duplicated folder.\n",
    "As a result I'm having 52593 images with 179 folder (labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Folder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Folder_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm using this helper function to seperate this dataset to train/test data with a 20% split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_dataset_into_test_and_train_sets(all_data_dir, training_data_dir, testing_data_dir, testing_data_pct):\n",
    "    # Recreate testing and training directories\n",
    "    if testing_data_dir.count('/') > 1:\n",
    "        shutil.rmtree(testing_data_dir, ignore_errors=False)\n",
    "        os.makedirs(testing_data_dir)\n",
    "        print(\"Successfully cleaned directory \" + testing_data_dir)\n",
    "    else:\n",
    "        print(\"Refusing to delete testing data directory \" + testing_data_dir + \" as we prevent you from doing stupid things!\")\n",
    "\n",
    "    if training_data_dir.count('/') > 1:\n",
    "        shutil.rmtree(training_data_dir, ignore_errors=False)\n",
    "        os.makedirs(training_data_dir)\n",
    "        print(\"Successfully cleaned directory \" + training_data_dir)\n",
    "    else:\n",
    "        print(\"Refusing to delete testing data directory \" + training_data_dir + \" as we prevent you from doing stupid things!\")\n",
    "\n",
    "    num_training_files = 0\n",
    "    num_testing_files = 0\n",
    "\n",
    "    for subdir, dirs, files in os.walk(all_data_dir):\n",
    "        category_name = os.path.basename(subdir)\n",
    "\n",
    "        # Don't create a subdirectory for the root directory\n",
    "        print(category_name + \" vs \" + os.path.basename(all_data_dir))\n",
    "        if category_name == os.path.basename(all_data_dir):\n",
    "            continue\n",
    "\n",
    "        training_data_category_dir = training_data_dir + '/' + category_name\n",
    "        testing_data_category_dir = testing_data_dir + '/' + category_name\n",
    "\n",
    "        if not os.path.exists(training_data_category_dir):\n",
    "            os.mkdir(training_data_category_dir)\n",
    "\n",
    "        if not os.path.exists(testing_data_category_dir):\n",
    "            os.mkdir(testing_data_category_dir)\n",
    "\n",
    "        for file in files:\n",
    "            input_file = os.path.join(subdir, file)\n",
    "            if np.random.rand(1) < testing_data_pct:\n",
    "                shutil.copy(input_file, testing_data_dir + '/' + category_name + '/' + file)\n",
    "                num_testing_files += 1\n",
    "            else:\n",
    "                shutil.copy(input_file, training_data_dir + '/' + category_name + '/' + file)\n",
    "                num_training_files += 1\n",
    "\n",
    "    print(\"Processed \" + str(num_training_files) + \" training files.\")\n",
    "    print(\"Processed \" + str(num_testing_files) + \" testing files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset_into_test_and_train_sets('E:/StockX/','E:/StockX_Train/','E:/StockX_Test/',0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wrapping up data processing portion here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
